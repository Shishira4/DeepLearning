{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Linear Regression</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Linear regression is used in which value of dependent variable is predicted\n",
    "through independent variables. A relationship is formed by mapping the dependent and independent\n",
    "variable on a line and that line is called regression line which is represented by Y= a*X + b.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression Algorithm can be used in ML when the data is present in a continuous fashion\n",
    "It predicts results of data such as: \n",
    "\n",
    "If 1 pen costs 3 rupees<br>\n",
    "2 pens costs 6 rupees<br>\n",
    "3 pens cost 9 rupees<br>\n",
    "4 pens cost 12 rupees<br>\n",
    "how much would 8 pens cost?<br>\n",
    "\n",
    "It will formulate that <b>y=3x</b> and predict that <b>8 pens would cost 24 rupees</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression Algorithm</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "height=[[4.0],[5.0],[6.0],[7.0],[8.0],[9.0],[10.0]]\n",
    "weight=[  8, 10 , 12, 14, 16, 18, 20]\n",
    "plt.scatter(height,weight,color='black')\n",
    "plt.xlabel(\"height\")\n",
    "plt.ylabel(\"weight\")\n",
    "reg=linear_model.LinearRegression()\n",
    "reg.fit(height,weight)\n",
    "X_height=[[12.0]]\n",
    "print(reg.predict(X_height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><h5>Observe that the graph is linear</h5></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In logistic regression we have lot of data whose classification is done by\n",
    "building an equation. \n",
    "\n",
    "This method is used to find the discrete dependent variable from the set of\n",
    "independent variables. Its goal is to find the best fit set of parameters. \n",
    "\n",
    "In this classifier, each feature is\n",
    "multiplied by a weight and then all are added. Then the result is passed to sigmoid function which\n",
    "produces the binary output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
    "y = [0,1,1,1,0,0,1]\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X,y)\n",
    "X_marks=[[100]]\n",
    "print(classifier.predict(X_marks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It belongs to supervised learning algorithm. Decision tree can be used to\n",
    "classification and regression both having a tree like structure. \n",
    "\n",
    "In a decision tree building algorithm first\n",
    "the best attribute of dataset is placed at the root, then training dataset is split into subsets. Splitting of\n",
    "data depends on the features of datasets. \n",
    "This process is done until the whole data is classified and we\n",
    "find leaf node at each branch. Information gain can be calculated to find which feature is giving us the\n",
    "highest information gain. \n",
    "\n",
    "Decision trees are built for making a training model which can be used to\n",
    "predict class or the value of target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
    "y = [0,1,1,1,0,0,1]\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X,y)\n",
    "X_marks=[[20]]\n",
    "print(classifier.predict(X_marks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve both classification and regression problems.\n",
    "\n",
    "The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
    "y = [0,1,1,1,0,0,1]\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
    "classifier.fit(X,y) \n",
    "X_marks=[[50]]\n",
    "print(classifier.predict(X_marks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest consists of a large number of individual decision trees that operate as an ensemble. \n",
    "\n",
    "Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes this modelâ€™s prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
    "y = [0,1,1,1,0,0,1]\n",
    "RandomForestRegModel = RandomForestRegressor()\n",
    "RandomForestRegModel.fit(X,y)\n",
    "classifier.fit(X,y)\n",
    "X_marks=[[70]]\n",
    "print(RandomForestRegModel.predict(X_marks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of SVM is to divide the class into 2 datasets to find the maximum marginal hyperplanes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "X = [[30],[40],[50],[60],[20],[10],[70]]\n",
    "y = [0,1,1,1,0,0,1]\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X,y)\n",
    "X_marks=[[55]]\n",
    "print(classifier.predict(X_marks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
